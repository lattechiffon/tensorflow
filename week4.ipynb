{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4주차: 정규화\n",
    "#### 고용국"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정규화 없는 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\latte\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(128, activation=tf.nn.leaky_relu))\n",
    "model.add(keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.5064 - acc: 0.8234\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.3880 - acc: 0.8603\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.3554 - acc: 0.8709\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.3328 - acc: 0.8778\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.3131 - acc: 0.8858\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.2994 - acc: 0.8893\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.2939 - acc: 0.8916\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2799 - acc: 0.8956\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.2726 - acc: 0.8985\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2646 - acc: 0.9020\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.2561 - acc: 0.9047\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2485 - acc: 0.9072\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.2466 - acc: 0.9078\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2411 - acc: 0.9096\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2348 - acc: 0.9134\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2302 - acc: 0.9142\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.2263 - acc: 0.9162\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2218 - acc: 0.9175\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2188 - acc: 0.9176\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2130 - acc: 0.9204\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2096 - acc: 0.9218\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.2073 - acc: 0.9229\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2049 - acc: 0.9231\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.2026 - acc: 0.9246\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1956 - acc: 0.9266\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1924 - acc: 0.9277\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1938 - acc: 0.9270\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1881 - acc: 0.9293\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1855 - acc: 0.9299\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1832 - acc: 0.9311\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1805 - acc: 0.9331\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1784 - acc: 0.9334\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1760 - acc: 0.9332\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1734 - acc: 0.9360\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1701 - acc: 0.9368\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1685 - acc: 0.9359\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1648 - acc: 0.9389\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1644 - acc: 0.9387\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1567 - acc: 0.9416\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1613 - acc: 0.9399\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1572 - acc: 0.9406\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1553 - acc: 0.9417\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.1540 - acc: 0.9415\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1538 - acc: 0.9428\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1527 - acc: 0.9440\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1469 - acc: 0.9446\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1466 - acc: 0.9452\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1464 - acc: 0.9449\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.1414 - acc: 0.9473\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1401 - acc: 0.9476\n",
      "10000/10000 [==============================] - 0s 44us/sample - loss: 0.4216 - acc: 0.8818\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'],\n",
    "              optimizer=keras.optimizers.Adam(lr=1e-3))\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=50)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "\n",
    "predictions = model.predict(test_images)\n",
    "results.append([test_accuracy, predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배치 정규화 적용 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation(tf.nn.leaky_relu))\n",
    "model.add(keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\latte\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.4756 - acc: 0.8322\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.3848 - acc: 0.8618\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.3514 - acc: 0.8731\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.3295 - acc: 0.8800\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.3141 - acc: 0.8851\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.3010 - acc: 0.8898\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2870 - acc: 0.8949\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2763 - acc: 0.8980\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2681 - acc: 0.9013\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.2600 - acc: 0.9030\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.2535 - acc: 0.9068\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.2453 - acc: 0.9108\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2401 - acc: 0.9111\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.2346 - acc: 0.9136\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.2275 - acc: 0.9166\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.2236 - acc: 0.9176\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.2173 - acc: 0.9190\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2144 - acc: 0.9201\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2094 - acc: 0.9227\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2054 - acc: 0.9247\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2019 - acc: 0.9244\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.1968 - acc: 0.9262\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.1959 - acc: 0.9269\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.1918 - acc: 0.9284\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.1871 - acc: 0.9303\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.1857 - acc: 0.9315\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.1829 - acc: 0.9316\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.1815 - acc: 0.9321\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.1783 - acc: 0.9329\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.1719 - acc: 0.9367\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.1724 - acc: 0.9356\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.1701 - acc: 0.9363\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.1664 - acc: 0.9381\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.1636 - acc: 0.9395\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.1616 - acc: 0.9394\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.1613 - acc: 0.9404\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.1572 - acc: 0.9413\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1564 - acc: 0.9418\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1535 - acc: 0.9426\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1537 - acc: 0.9427\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 0.1487 - acc: 0.9450\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1472 - acc: 0.9451\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.1464 - acc: 0.9447\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.1444 - acc: 0.9454\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.1406 - acc: 0.9463\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.1398 - acc: 0.9477\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.1368 - acc: 0.9496\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.1367 - acc: 0.9482\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.1375 - acc: 0.9482\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.1337 - acc: 0.9505\n",
      "10000/10000 [==============================] - 1s 50us/sample - loss: 0.4274 - acc: 0.8790\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'],\n",
    "              optimizer=keras.optimizers.Adam(lr=1e-3))\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=50)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "\n",
    "predictions = model.predict(test_images)\n",
    "results.append([test_accuracy, predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 드롭아웃 적용 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\latte\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dropout(rate=0.2))\n",
    "model.add(keras.layers.Dense(128, activation=tf.nn.leaky_relu))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.6365 - acc: 0.7751\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.5114 - acc: 0.8176\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4826 - acc: 0.8263\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4685 - acc: 0.8296\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4593 - acc: 0.8321\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4527 - acc: 0.8368\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4462 - acc: 0.8375\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4428 - acc: 0.8395\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4377 - acc: 0.8411\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4358 - acc: 0.8410\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4327 - acc: 0.8413\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4308 - acc: 0.8438\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4288 - acc: 0.8442\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4251 - acc: 0.8453\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4242 - acc: 0.8464\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4260 - acc: 0.8464\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4233 - acc: 0.8470\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4191 - acc: 0.8480\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4208 - acc: 0.8463\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4203 - acc: 0.8475\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4189 - acc: 0.8468\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4226 - acc: 0.8456\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4178 - acc: 0.8486\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4165 - acc: 0.8482\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4135 - acc: 0.8497\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4142 - acc: 0.8489\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4132 - acc: 0.8496\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4112 - acc: 0.8506\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4117 - acc: 0.8492\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.4095 - acc: 0.8498\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4142 - acc: 0.8474\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4125 - acc: 0.8509\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4120 - acc: 0.8501\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4109 - acc: 0.8492\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4100 - acc: 0.8508\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4109 - acc: 0.8505\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4089 - acc: 0.8498\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4098 - acc: 0.8508\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4071 - acc: 0.8502\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.4081 - acc: 0.8515\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4105 - acc: 0.8506\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4100 - acc: 0.8510\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4070 - acc: 0.8529\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4094 - acc: 0.8499\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4095 - acc: 0.8509\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4048 - acc: 0.8507\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4067 - acc: 0.8501\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4084 - acc: 0.8520\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4076 - acc: 0.8515\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4029 - acc: 0.8515\n",
      "10000/10000 [==============================] - 1s 51us/sample - loss: 0.3702 - acc: 0.8652\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'],\n",
    "              optimizer=keras.optimizers.Adam(lr=1e-3))\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=50)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "\n",
    "predictions = model.predict(test_images)\n",
    "results.append([test_accuracy, predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 확장 적용 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(1, 28, 28)))\n",
    "model.add(keras.layers.Dense(128, activation=tf.nn.leaky_relu))\n",
    "model.add(keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\latte\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:923: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (60000, 1, 28, 28) (28 channels).\n",
      "  ' channels).')\n",
      "c:\\users\\latte\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras_preprocessing\\image\\numpy_array_iterator.py:127: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (60000, 1, 28, 28) (28 channels).\n",
      "  str(self.x.shape[channels_axis]) + ' channels).')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.8050 - acc: 0.7115\n",
      "Epoch 2/50\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.6152 - acc: 0.7800 1s - loss: 0.6151 \n",
      "Epoch 3/50\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.5696 - acc: 0.7934\n",
      "Epoch 4/50\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.5441 - acc: 0.8036\n",
      "Epoch 5/50\n",
      "469/469 [==============================] - 41s 86ms/step - loss: 0.5195 - acc: 0.8130\n",
      "Epoch 6/50\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.5090 - acc: 0.8142\n",
      "Epoch 7/50\n",
      "469/469 [==============================] - 41s 86ms/step - loss: 0.4963 - acc: 0.8202\n",
      "Epoch 8/50\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.4876 - acc: 0.8212\n",
      "Epoch 9/50\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.4766 - acc: 0.8260\n",
      "Epoch 10/50\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.4796 - acc: 0.8255\n",
      "Epoch 11/50\n",
      "469/469 [==============================] - 41s 88ms/step - loss: 0.4674 - acc: 0.8280\n",
      "Epoch 12/50\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.4664 - acc: 0.8289 2s - lo\n",
      "Epoch 13/50\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.4566 - acc: 0.8341\n",
      "Epoch 14/50\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.4505 - acc: 0.8344\n",
      "Epoch 15/50\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.4508 - acc: 0.8330 2s -\n",
      "Epoch 16/50\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.4451 - acc: 0.8352\n",
      "Epoch 17/50\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.4423 - acc: 0.8353\n",
      "Epoch 18/50\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.4360 - acc: 0.8389 0s - loss: 0.4358 - acc: 0.839\n",
      "Epoch 19/50\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.4386 - acc: 0.8379\n",
      "Epoch 20/50\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.4368 - acc: 0.8385\n",
      "Epoch 21/50\n",
      "469/469 [==============================] - 41s 86ms/step - loss: 0.4331 - acc: 0.8393 0s - loss: 0.4332 - acc: 0\n",
      "Epoch 22/50\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.4285 - acc: 0.8419\n",
      "Epoch 23/50\n",
      "469/469 [==============================] - 41s 86ms/step - loss: 0.4261 - acc: 0.8433\n",
      "Epoch 24/50\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.4266 - acc: 0.8427\n",
      "Epoch 25/50\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.4238 - acc: 0.8433\n",
      "Epoch 26/50\n",
      "469/469 [==============================] - 41s 88ms/step - loss: 0.4213 - acc: 0.8447\n",
      "Epoch 27/50\n",
      "469/469 [==============================] - 41s 86ms/step - loss: 0.4181 - acc: 0.8454\n",
      "Epoch 28/50\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.4184 - acc: 0.8454\n",
      "Epoch 29/50\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.4180 - acc: 0.8455\n",
      "Epoch 30/50\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.4153 - acc: 0.8463\n",
      "Epoch 31/50\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.4139 - acc: 0.8462\n",
      "Epoch 32/50\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.4111 - acc: 0.8479 2\n",
      "Epoch 33/50\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.4122 - acc: 0.8486\n",
      "Epoch 34/50\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.4078 - acc: 0.8493\n",
      "Epoch 35/50\n",
      "469/469 [==============================] - 41s 86ms/step - loss: 0.4088 - acc: 0.8472\n",
      "Epoch 36/50\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.4068 - acc: 0.8495\n",
      "Epoch 37/50\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.4089 - acc: 0.8494\n",
      "Epoch 38/50\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.4049 - acc: 0.8530\n",
      "Epoch 39/50\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.3987 - acc: 0.8515\n",
      "Epoch 40/50\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.4005 - acc: 0.8511\n",
      "Epoch 41/50\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.3985 - acc: 0.8523\n",
      "Epoch 42/50\n",
      "469/469 [==============================] - 41s 88ms/step - loss: 0.4016 - acc: 0.8522\n",
      "Epoch 43/50\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.3969 - acc: 0.8514\n",
      "Epoch 44/50\n",
      "469/469 [==============================] - 41s 86ms/step - loss: 0.3971 - acc: 0.8521\n",
      "Epoch 45/50\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.3960 - acc: 0.8533 1s - loss: 0.3962 \n",
      "Epoch 46/50\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.3941 - acc: 0.8529\n",
      "Epoch 47/50\n",
      "469/469 [==============================] - 41s 86ms/step - loss: 0.3932 - acc: 0.8542\n",
      "Epoch 48/50\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.3933 - acc: 0.8544\n",
      "Epoch 49/50\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.3913 - acc: 0.8549 2s - l\n",
      "Epoch 50/50\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.3892 - acc: 0.8553\n",
      "10000/10000 [==============================] - 0s 48us/sample - loss: 0.3927 - acc: 0.8528\n"
     ]
    }
   ],
   "source": [
    "train_images = train_images.reshape(60000, 1, 28, 28)\n",
    "test_images = test_images.reshape(10000, 1, 28, 28)\n",
    "\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'],\n",
    "              optimizer=keras.optimizers.Adam(lr=1e-3))\n",
    "\n",
    "imgGenerator = keras.preprocessing.image.ImageDataGenerator(rotation_range=20,\n",
    "                                                            width_shift_range=0.3,\n",
    "                                                            height_shift_range=0.3,\n",
    "                                                            shear_range=0.3,\n",
    "                                                            vertical_flip=True,\n",
    "                                                            fill_mode='nearest')\n",
    "imgGenerator.fit(train_images)\n",
    "\n",
    "history = model.fit_generator(imgGenerator.flow(train_images, train_labels, batch_size=128), steps_per_epoch=1, epochs=50)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "\n",
    "predictions = model.predict(test_images)\n",
    "results.append([test_accuracy, predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 조기 종료 적용 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(128, activation=tf.nn.leaky_relu))\n",
    "model.add(keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.5042 - acc: 0.8221\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.3871 - acc: 0.8612\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.3535 - acc: 0.8725\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.3333 - acc: 0.8790\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.3186 - acc: 0.8838\n",
      "10000/10000 [==============================] - 1s 51us/sample - loss: 0.3710 - acc: 0.8699\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.3037 - acc: 0.8890\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.2951 - acc: 0.8913\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.2849 - acc: 0.8936\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.2756 - acc: 0.8988\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.2694 - acc: 0.9004\n",
      "10000/10000 [==============================] - 0s 42us/sample - loss: 0.3371 - acc: 0.8798\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.2606 - acc: 0.9035\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.2542 - acc: 0.9061\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.2495 - acc: 0.9077\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.2435 - acc: 0.9101\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.2391 - acc: 0.9102\n",
      "10000/10000 [==============================] - 0s 43us/sample - loss: 0.3740 - acc: 0.8640\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'],\n",
    "              optimizer=keras.optimizers.Adam(lr=1e-3))\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "prev_test_accuracy = test_accuracy\n",
    "model.save_weights('fashion_mnist_model.h5')\n",
    "\n",
    "while True:\n",
    "    history = model.fit(train_images, train_labels, epochs=5)\n",
    "    test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "\n",
    "    if test_accuracy < prev_test_accuracy:\n",
    "        break\n",
    "\n",
    "    prev_test_accuracy = test_accuracy\n",
    "    model.save_weights('fashion_mnist_model.h5')\n",
    "\n",
    "model.load_weights('fashion_mnist_model.h5')\n",
    "\n",
    "predictions = model.predict(test_images)\n",
    "results.append([test_accuracy, predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 앙상블 적용 모델\n",
    "멀티프로세싱 적용 시 GPU CUDA 할당 오류 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = keras.Sequential()\n",
    "model_1.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model_1.add(keras.layers.Dense(128, activation=tf.nn.leaky_relu))\n",
    "model_1.add(keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "model_2 = keras.Sequential()\n",
    "model_2.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model_2.add(keras.layers.Dense(128))\n",
    "model_2.add(keras.layers.BatchNormalization())\n",
    "model_2.add(keras.layers.Activation(tf.nn.leaky_relu))\n",
    "model_2.add(keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "model_3 = keras.Sequential()\n",
    "model_3.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model_3.add(keras.layers.Dropout(rate=0.2))\n",
    "model_3.add(keras.layers.Dense(128, activation=tf.nn.leaky_relu))\n",
    "model_3.add(keras.layers.Dropout(rate=0.5))\n",
    "model_3.add(keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.5026 - acc: 0.8241\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.3884 - acc: 0.8606\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.3532 - acc: 0.8726\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.3327 - acc: 0.8770\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.3159 - acc: 0.8845\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.3040 - acc: 0.8881\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2925 - acc: 0.8923\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2833 - acc: 0.8951\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.2737 - acc: 0.8980\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2672 - acc: 0.9000\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2619 - acc: 0.9031\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2549 - acc: 0.9050\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2490 - acc: 0.9064\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.2431 - acc: 0.9098\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.2379 - acc: 0.9113\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.2328 - acc: 0.9124\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2272 - acc: 0.9136\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2240 - acc: 0.9152\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2201 - acc: 0.9171\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2145 - acc: 0.9194\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.2140 - acc: 0.9195\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2096 - acc: 0.9211\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2070 - acc: 0.9219\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.2037 - acc: 0.9242\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1983 - acc: 0.9255\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1948 - acc: 0.9279\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1916 - acc: 0.9273\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1911 - acc: 0.9286\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1862 - acc: 0.9315\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1854 - acc: 0.9314\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1798 - acc: 0.9327\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1791 - acc: 0.9330\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1745 - acc: 0.9342\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1747 - acc: 0.9349\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1739 - acc: 0.9348\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1666 - acc: 0.9384\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1641 - acc: 0.9391\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1646 - acc: 0.9377\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1614 - acc: 0.9400\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1597 - acc: 0.9401\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1581 - acc: 0.9419\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1555 - acc: 0.9419\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1523 - acc: 0.9432\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1504 - acc: 0.9437\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1485 - acc: 0.9446\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1456 - acc: 0.9454\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1452 - acc: 0.9462\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1426 - acc: 0.9471\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1421 - acc: 0.9475\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1414 - acc: 0.9469\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.4765 - acc: 0.8313\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.3841 - acc: 0.8603\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.3511 - acc: 0.8723\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.3291 - acc: 0.8812\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.3107 - acc: 0.8871\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2981 - acc: 0.8909\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2882 - acc: 0.8941\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2775 - acc: 0.8991\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.2695 - acc: 0.8990\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2608 - acc: 0.9033\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.2520 - acc: 0.9079\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.2450 - acc: 0.9086\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2406 - acc: 0.9115\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.2345 - acc: 0.9140\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.2272 - acc: 0.9144\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.2262 - acc: 0.9160\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.2193 - acc: 0.9183\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.2137 - acc: 0.9206\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2101 - acc: 0.9218\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.2064 - acc: 0.9227\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.2000 - acc: 0.9268\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.1987 - acc: 0.9262\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.1960 - acc: 0.9264\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1919 - acc: 0.9283\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1864 - acc: 0.9303\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1845 - acc: 0.9299\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1815 - acc: 0.9318\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1794 - acc: 0.9316\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1783 - acc: 0.9335\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1731 - acc: 0.9362\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1715 - acc: 0.9358\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1678 - acc: 0.9373\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1673 - acc: 0.9373\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1624 - acc: 0.9393\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1597 - acc: 0.9407\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1602 - acc: 0.9406\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1576 - acc: 0.9416\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1537 - acc: 0.9423\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1538 - acc: 0.9429\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1527 - acc: 0.9432\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1472 - acc: 0.9439\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1462 - acc: 0.9457\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1451 - acc: 0.9468\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1421 - acc: 0.9468\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1416 - acc: 0.9470\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1415 - acc: 0.9468\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1405 - acc: 0.9469\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1378 - acc: 0.9498\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1362 - acc: 0.9493\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1343 - acc: 0.9504\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.6357 - acc: 0.7740\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.5103 - acc: 0.8168\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4851 - acc: 0.8253\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4728 - acc: 0.8278\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4624 - acc: 0.8329\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.4582 - acc: 0.8332\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4497 - acc: 0.8363\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4455 - acc: 0.8400\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.4411 - acc: 0.8407\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4420 - acc: 0.8384\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4356 - acc: 0.8407\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.4323 - acc: 0.8425\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4318 - acc: 0.8426\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4311 - acc: 0.8427\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4240 - acc: 0.8457\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4261 - acc: 0.8453\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.4259 - acc: 0.8450\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4230 - acc: 0.8449\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4216 - acc: 0.8456\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.4209 - acc: 0.8461\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4172 - acc: 0.8471\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4200 - acc: 0.8458\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.4154 - acc: 0.8491\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4190 - acc: 0.8479\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.4183 - acc: 0.8483\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.4147 - acc: 0.8474\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.4147 - acc: 0.8487\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4173 - acc: 0.8481\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.4143 - acc: 0.8486\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.4146 - acc: 0.8487\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4141 - acc: 0.8490\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.4136 - acc: 0.8488\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4109 - acc: 0.8499\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4144 - acc: 0.8477\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4085 - acc: 0.8509\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4124 - acc: 0.8495\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4090 - acc: 0.8505\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.4111 - acc: 0.8512\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.4051 - acc: 0.8520\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.4084 - acc: 0.8509\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.4085 - acc: 0.8515\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.4123 - acc: 0.8498\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4069 - acc: 0.8528\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.4118 - acc: 0.8495\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.4091 - acc: 0.8517\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.4070 - acc: 0.8499\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4086 - acc: 0.8503\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4050 - acc: 0.8520\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.4063 - acc: 0.8507\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.4073 - acc: 0.8522\n",
      "10000/10000 [==============================] - 1s 54us/sample - loss: 0.4456 - acc: 0.8796\n",
      "10000/10000 [==============================] - 1s 60us/sample - loss: 0.5223 - acc: 0.8580\n",
      "10000/10000 [==============================] - 1s 57us/sample - loss: 0.3714 - acc: 0.8635\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(loss=keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'],\n",
    "                optimizer=keras.optimizers.Adam(lr=1e-3))\n",
    "model_2.compile(loss=keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'],\n",
    "                optimizer=keras.optimizers.Adam(lr=1e-3))\n",
    "model_3.compile(loss=keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'],\n",
    "                optimizer=keras.optimizers.Adam(lr=1e-3))\n",
    "\n",
    "history_1 = model_1.fit(train_images, train_labels, epochs=50)\n",
    "history_2 = model_2.fit(train_images, train_labels, epochs=50)\n",
    "history_3 = model_3.fit(train_images, train_labels, epochs=50)\n",
    "\n",
    "test_loss_1, test_accuracy_1 = model_1.evaluate(test_images, test_labels)\n",
    "test_loss_2, test_accuracy_2 = model_2.evaluate(test_images, test_labels)\n",
    "test_loss_3, test_accuracy_3 = model_3.evaluate(test_images, test_labels)\n",
    "\n",
    "predictions_1 = model_1.predict(test_images)\n",
    "predictions_2 = model_2.predict(test_images)\n",
    "predictions_3 = model_3.predict(test_images)\n",
    "predictions = 0.4 * predictions_1 + 0.3 * predictions_2 + 0.3 * predictions_3\n",
    "\n",
    "count = 0\n",
    "for i in range(10000):\n",
    "    if np.argmax(predictions[i]) == test_labels[i]:\n",
    "        count += 1\n",
    "\n",
    "results.append([count / 10000.0, predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (Epochs: 50)\n",
      "정규화 없는 모델: 0.8818\n",
      "배치 정규화 적용 모델: 0.879\n",
      "드롭아웃 적용 모델: 0.8652\n",
      "데이터 확장 적용 모델: 0.8528\n",
      "조기 종료 적용 모델: 0.864\n",
      "앙상블 적용 모델: 0.8883\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy (Epochs: 50)')\n",
    "print('정규화 없는 모델:', results[0][0])\n",
    "print('배치 정규화 적용 모델:', results[1][0])\n",
    "print('드롭아웃 적용 모델:', results[2][0])\n",
    "print('데이터 확장 적용 모델:', results[3][0])\n",
    "print('조기 종료 적용 모델:', results[4][0])\n",
    "print('앙상블 적용 모델:', results[5][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
